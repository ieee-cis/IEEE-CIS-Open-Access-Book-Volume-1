\newpage
\section{Exercises}
\newcounter{qcounter}
%\begin{list}{
%\textbf{Question \arabic{qcounter}:}~}{\usecounter{qcounter}}

\begin{enumerate}

\item \noindent Considering the focus on convolutional neural networks, we can highlight convolution as a basic operator. For a basic understanding of the application and effect of convolution, manually convolute the kernel $\left[\begin{smallmatrix}
0 & 2 & 3\\
0 & 1 & 0\\
3 & 0 & 2
\end{smallmatrix}\right]$ onto the image matrix $\left[\begin{smallmatrix}
1 & 2 & 0\\
3 & 0 & 0\\
4 & 1 & 0
\end{smallmatrix}\right]$. Use padding with $p_m = p_n = 1$ and stride=1. Use the value of zero for the pixels added through padding.


\item \noindent In the context of applications with images, each convolution layer can identify a level of detail in the image. For example, in the initial layers typically identify more general elements of the images, such as lines, edges and corners. Some pre-determined filters, or convolutions, that have the edge detection property are Sobel and Prewitt. Each of these operators is composed of to kernels as shown below:


\begin{itemize}
\item Prewitt Operators. 

$G_x= \left[\begin{smallmatrix}
-1 & 0 & 1\\
-1 & 0 & 1\\
-1 & 0 & 1
\end{smallmatrix}\right]$

$G_y = \left[\begin{smallmatrix}
-1 & -1 & -1\\
 0 &  0 &  0\\
 1 &  1 &  1
\end{smallmatrix}\right]$

\item Sobel Operators. 

$G_x= \left[\begin{smallmatrix}
-1 & 0 & 1\\
-2 & 0 & 2\\
-1 & 0 & 1
\end{smallmatrix}\right]$

$G_y = \left[\begin{smallmatrix}
-1 & -2 & -1\\
 0 &  0 &  0\\
 1 &  2 &  1
\end{smallmatrix}\right]$

\end{itemize}

By applying each of the two Prewitt kernels on the image and summing the modulus of the two resulting matrices to get a single output matrix, it is possible to determine the edges in the image. A similar procedure can be used with the Sobel operators, which also result in detection of edges. Apply the Prewitt and Sobel operators in the image represented by the matrix below, using no padding and stride=1:

        $\left[\begin{smallmatrix}
        1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
        1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
        1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
        1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
        1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
        1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
        \end{smallmatrix}\right]$ 

\item \noindent One of the techniques used in image applications using convolutional neural networks is to reduce the size of inputs across layers, which can reduce computational costs. To perform this reduction we can use strides in the application of convolution. Perform the convolution between kernel $\left[\begin{smallmatrix}
0 & 2 & 3 \\
0 & 1 & 0 \\
3 & 0 & 2 
\end{smallmatrix}\right]$ and matrix  $\left[\begin{smallmatrix}
1 & 2 & 0 & 3 & 0\\
3 & 0 & 0 & 1 & 0\\
4 & 1 & 0 & 2 & 1
\end{smallmatrix}\right]$, first using stride 1 and then with stride 2 to assess the effect of this technique. Use no padding.


\item \noindent During image processing in convolutional neural networks, there are steps in which the inputs and outputs of the convolution layers need to keep the same size, and one way to have this control is to use padding in the application of the convolution. With the same kernel and matrix as in the previous exercise, determine a padding to ensure that the result remains the same size as the original matrix, and then apply the convolution using this padding.


%\item \noindent The LeNeT network is one of the simplest convolutional networks, being possible to implement without the use of frameworks and still obtain good results in a short period of testing time. Using the MNIST dataset build a LeNet network for digit classification, with and without framework. Evaluate the implementation complexity in the two cases and the results considering the same input and training parameters.
%
%
%\item The construction of a Convolutional Neural Network for classification of cats and dogs images is a very common exercise, usually performed to demonstrate the most important ideas in the functioning of CNNs. That said, use some dataset that contains images of dogs and cats (like the one available in the TensorFlow library\footnote{\url{https://www.tensorflow.org/datasets/catalog/cats_vs_dogs}}) and use it to compare the performance of the AlexNet, VGG and GoogleLeNet networks (remembering that these models are already available, fully pre-trained, in libraries such as Keras\footnote{\url{https://keras.io/api/applications/}} and Pytorch\footnote{\url{https://pytorch.org/vision/stable/models.html}}).
%
%
%\item As explained in the Transfer Learning section \ref{transferlearning}, Convolutional Neural Networks with large and complex architectures can take a long time and consume large amounts of processing and memory in their training. Using pre-trained networks can help us, as we can use them directly or train them from that point on. Like in the previous exercise, use pre-trained models from some library, but this time using a dataset with a larger number of classes (for example, the cifar100 dataset\footnote{\url{https://www.tensorflow.org/datasets/catalog/cifar100}} that contains 100 classes). Also check the difference in performance of each model, taking into account its complexity and the number of classes.
%\end{list}
\end{enumerate}